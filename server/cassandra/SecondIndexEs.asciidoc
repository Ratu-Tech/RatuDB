== Second Index ES 二级索引到
二级索引是单独建立一个索引表，将索引数据存入其他位置，在cassandra自己本身实现了SASI,也是实现了二级索引的一种形式。

V4.1.2.4 分支实现的是将索引数据存入Opensearch或者Elasticsearch。

== 索引原理说明
举例：在Cassandra中存储了这么一张车辆信息表
image:doc/img/3.png[]

如果单纯里边关系型数据库，查询主键，在大数据量的情况下，这种性能影响不大。
索引大数量情况下的索引成了问题的关键，比如，希望查询车牌号的情况下，如果车牌号，就需要为车牌号这个字段增加索引才可以。

在这种情况下，就可以利用一下倒排索引的做法，避免全表扫描。
所以索引写入opensearch或者elasticsearch就整合优势，cassandra作为了宽表的存储，es进行索引查询。
二级索引写入之后，假如要查询车辆品牌为`宝马`的车辆数据提前的倒排索引会是如下这个样子：

image:doc/img/4.png[]

可以快速定位到有相关数据的位置。


== 还需要做的事情

1、目前还不知道多条件的组合查询，需要增加bool查询的支持。
2、同步过去的数据，目前还不支持子字段。
3、在cql客户端尝试增加es的聚合结果支持。

== 如何使用
=== 1、Cql客户端 数据写入
==== 首先创建一个keyspace。
-----
CREATE KEYSPACE demo
WITH REPLICATION = {'class': 'SimpleStrategy', 'replication_factor': 1};
-----

==== 再创建一张表，在这个keyspace
----
CREATE TABLE demo.tweets (
   id INT PRIMARY KEY,
   user TEXT,
   body TEXT,
   time TIMESTAMP,
   latitude FLOAT,
   longitude FLOAT
);
----
==== 创建表只需要加一个 PRIMARY KEY 主键就可以了，比如复合主键这种就不需要了，也会造成一些其他问题。

==== 创建二级索引
----
CREATE CUSTOM INDEX tweets_index ON demo.tweets ()
USING 'org.apache.second.ElasticSecondaryIndex'
WITH OPTIONS = {
   'refresh_seconds': '10',
   'schema': '{
      fields: {
         id: {type: "integer"},
         user: {type: "text"},
         body: {type: "text", analyzer: "english"},
         time: {type: "date", pattern: "yyyy-MM-dd"},
         latitude: {type: "float"},
         longitude: {type:"float"}
      }
   }'
};
----
==== 这是一个典型的全表索引的例子，`schema` 里是配置的是索引到Opensearch或者Elasticsearch的字段，要注意 `type` 里边的字段类型，这个需要严格遵守Elasticsearch里的字段类型。
==== `refresh_sconds` 是配置Elasticsearch 或者Opensearch 里的 刷新频率。如果在数据量大的情况下，这个配置的调整我个人认为还是很有必要的。

==== 再说明一点，目前配置，只支持自定义字段类型和自定义分词器。


==== 这时候，就可以看到，在 Opensearch 或者 ES 里创建了索引，这时候还没有数据。创建的索引是  `keyspace名字.table名字` 这种形式。
举例上边的表，可以使用如下进行在ES或者Opensearch中查询
----
GET demo.tweets/_search
----
应该返回如下结果：
----
{
  "took": 2,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 0,
      "relation": "eq"
    },
    "max_score": null,
    "hits": []
  }
}
----

==== 接下来可以尝试写入几条数据
----
INSERT INTO demo.tweets (id, user, body, time,latitude,longitude) VALUES (1, 'fu', '123456', '2015-05-15',41.12,-71.34);

INSERT INTO demo.tweets (id, user, body, time,latitude,longitude) VALUES (2, 'fu', '123456', '2019-05-15',41.12,-71.34);

INSERT INTO demo.tweets (id, user, body, time,latitude,longitude) VALUES (3, 'lei', '123456', '2019-05-15',41.12,-71.34);
----

Cassandra 查询的数据是如下样子的：
----
cqlsh> select * from demo.tweets;

 id | body   | latitude | longitude | time                            | user
----+--------+----------+-----------+---------------------------------+------
  1 | 123456 |    41.12 |    -71.34 | 2015-05-14 16:00:00.000000+0000 |   fu
  2 | 123456 |    41.12 |    -71.34 | 2019-05-14 16:00:00.000000+0000 |   fu
  3 | 123456 |    41.12 |    -71.34 | 2019-05-14 16:00:00.000000+0000 |  lei

(3 rows)
cqlsh>
----

Opensearch或者Elasticsearch里边查询到的数据是如下样子的：
----
{
  "took": 16,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 3,
      "relation": "eq"
    },
    "max_score": 1,
    "hits": [
      {
        "_index": "demo.tweets",
        "_id": "2",
        "_score": 1,
        "_source": {
          "latitude": 41.12,
          "id": "2",
          "time": "2019-05-15",
          "body": "123456",
          "user": "fu",
          "longitude": -71.34
        }
      },
      {
        "_index": "demo.tweets",
        "_id": "1",
        "_score": 1,
        "_source": {
          "latitude": 41.12,
          "id": "1",
          "time": "2015-05-15",
          "body": "123456",
          "user": "fu",
          "longitude": -71.34
        }
      },
      {
        "_index": "demo.tweets",
        "_id": "3",
        "_score": 1,
        "_source": {
          "latitude": 41.12,
          "id": "3",
          "time": "2019-05-15",
          "body": "123456",
          "user": "lei",
          "longitude": -71.34
        }
      }
    ]
  }
}
----

==== 三条数据，可以进行对比一下，效果。


=== 2、ycsb 写入数据

ycsb是个cassandra的测试工具，以下是为了测试准备的keyspace、表和索引。
----
create keyspace ycsb
    WITH REPLICATION = {'class' : 'SimpleStrategy', 'replication_factor': 1 };


create table ycsb.usertable (
y_id varchar primary key,
field0 text,
field1 text,
field2 text,
field3 text,
field4 text,
field5 text,
field6 text,
field7 text,
field8 text,
field9 text);


CREATE CUSTOM INDEX usertable_index ON ycsb.usertable ()
USING 'org.apache.second.ElasticSecondaryIndex'
WITH OPTIONS = {
   'refresh_seconds': '1',
   'schema': '{
      fields: {
         field0: {type: "text"},
         field1: {type: "text"},
         field2: {type: "text"},
         field3: {type: "text"},
         field4: {type: "text"},
         field5: {type: "text"},
         field6: {type: "text"},
         field7: {type: "text"},
         field8: {type: "text"},
         field9: {type: "text"}
      }
   }'
};
----

以下是测试结果：
----
2023-06-28 10:57:55:488 10 sec: 8726 operations; 872.16 current ops/sec; est completion in 2 second [INSERT: Count=8728, Max=280831, Min=1460, Avg=53657.9, 90=102847, 99=192511, 99.9=274943, 99.99=280575]
2023-06-28 10:58:00:211 14 sec: 10000 operations; 269.74 current ops/sec; [CLEANUP: Count=50, Max=2238463, Min=0, Avg=44751.6, 90=4, 99=2238463, 99.9=2238463, 99.99=2238463] [INSERT: Count=1272, Max=242303, Min=1999, Avg=69652.12, 90=127103, 99=204159, 99.9=236287, 99.99=242303]
[OVERALL], RunTime(ms), 14728
[OVERALL], Throughput(ops/sec), 678.9788158609451
[TOTAL_GCS_G1_Young_Generation], Count, 3
[TOTAL_GC_TIME_G1_Young_Generation], Time(ms), 15
[TOTAL_GC_TIME_%_G1_Young_Generation], Time(%), 0.10184682237914178
[TOTAL_GCS_G1_Old_Generation], Count, 0
[TOTAL_GC_TIME_G1_Old_Generation], Time(ms), 0
[TOTAL_GC_TIME_%_G1_Old_Generation], Time(%), 0.0
[TOTAL_GCs], Count, 3
[TOTAL_GC_TIME], Time(ms), 15
[TOTAL_GC_TIME_%], Time(%), 0.10184682237914178
[CLEANUP], Operations, 50
[CLEANUP], AverageLatency(us), 44751.6
[CLEANUP], MinLatency(us), 0
[CLEANUP], MaxLatency(us), 2238463
[CLEANUP], 95thPercentileLatency(us), 18
[CLEANUP], 99thPercentileLatency(us), 2238463
[INSERT], Operations, 10000
[INSERT], AverageLatency(us), 55692.3614
[INSERT], MinLatency(us), 1460
[INSERT], MaxLatency(us), 280831
[INSERT], 95thPercentileLatency(us), 130367
[INSERT], 99thPercentileLatency(us), 194431
[INSERT], Return=OK, 10000
----

一万条随机生成的数据，写入cassandra大概在14秒。但是同步到Opensearch或者Elasticsearch，就不一定了。ES有refresh机制，就算写入了，也得看`refresh_seconds`的设置，时间越大看到的时间越长。
目前看对cassandra的性能不会造成影响。



=== 3、查询
起初的想法是希望lucene的原始语法做查询，但是Elasticsearch本身还是对lucene的一些语法做了调整的，所以就按照Elasticsearch的DSL语法进行兼容了。
==== 1、range查询
可以看如下cql语句：
----
<!--range查询-->
SELECT * FROM demo.tweets WHERE expr(tweets_index, '{
   query: {type: "range", field: "time", gte: "2014-04-25", lte: "2015-05-21"}
}');
----
----
query:代表的就是普通查询
type:代表的就是DSL的查询函数
field: 代表的是要查询的字段
gte:  大于等于
lte:  小于等于
----

==== 2、match 查询
----
<!--match查询-->
SELECT * FROM demo.tweets WHERE expr(tweets_index, '{
   query: {type: "match", field: "user", query: "lei"}
}');
----
这里边就是修改了type为match，在query的子字段里边增加了query，代表了要查询的值。

==== 3、match 查询 value 形式写法。
----
<!--match查询, value形式-->
SELECT * FROM demo.tweets WHERE expr(tweets_index, '{
   query: {type: "match", field: "user", value: "lei"}
}');
----
跟上边的写法，其实效果是一样的，就是把query写成了value。主要做这两种，是考虑以后增加boost的评分机制。

==== 4、match_phrase 查询
----
<!--match_phrase查询-->
SELECT * FROM demo.tweets WHERE expr(tweets_index, '{
   query: {type: "match_phrase", field: "user", query: "lei"}
}');
----
不多解释了，同match查询。

==== 5、match_phrase查询, value形式
----
<!--match_phrase查询, value形式-->
SELECT * FROM demo.tweets WHERE expr(tweets_index, '{
   query: {type: "match_phrase", field: "user", value: "lei"}
}');
----
不多解释了，同match查询。

==== 6、term 查询
----
<!--term查询 -->
SELECT * FROM demo.tweets WHERE expr(tweets_index, '{
   query: {type: "term", field: "user", value: "lei"}
}');
----
不多解释了，同match查询。

==== 7、强制刷新
----
<!--强制刷新后，range查询-->
SELECT * FROM demo.tweets WHERE expr(tweets_index, '{
   query: {type: "range", field: "time", gte: "2014-04-25", lte: "2015-05-21"},
   refresh: true
}') limit 100;
----
在查询的时候，增加了refresh这个配置，如果为true，会强制进行刷新索引。


=== 4、数据类型对应关系

|===
|CQL 类型 |对应Java类型 | ES类型 | 描述

|ascii
|String
|text
|asii字符串

|bigint
|long
|long
|64位整数

|blob
|ByteBuffer/byte[]
|text
|二进制数组 存入ES后，继续解析回成字符串存储

|boolean
|Boolean
|boolean
|布尔

|decimal
|BigDecimal
|float
|高精度小数

|double
|double
|double
|64位浮点小数

|float
|float
|float
|32位浮点数

|inet
|String
| ip
|ipv4或ipv6协议的ip地址(ipv6 暂时没测试)

|int
|int
|integer
|32位浮点数


|text
|String
|text
|utf-8编码的字符串

|timestamp
|Date
|date
|日期 Es 支持的日期，yyyy-MM-dd 或者  yyyy-MM-ddTHH:MM:SSZ ,代码内自动转换

|uuid
|UUID
|text
|UUID类型

|timeuuid
|UUID
|text
|时间相关的UUID

|varchar
|string
|text
|text的别名

|varint
|BigInteger
|text
|高精度整型

|duration
|String
|text
|以纳秒为单位的持续时间

|smallint
|Integer
|integer
|16位浮点数

|tinyint
|Integer
|integer
|8位浮点数

|list<T>
|String
|text
|存入到ES之后是array

|time
|long
|long
|纳秒级别的时间戳，格式 hh:mm:ss 的纳秒精准度，存入ES是64位整数

|set<T>
|Set<T>
|text
|存入到ES之后是array

|map<T,T>
|Map<T,T>
|nested
|复合结构，支持子查询
|===


=== 5、数据类型测试数据
====a.测试数据
-----
CREATE TABLE demo.tweets (
   id bigint PRIMARY KEY,
   user ascii,
   body blob,
   time TIMESTAMP,
   latitude FLOAT,
   longitude FLOAT,
   test boolean,
   test1 double,
   test2 inet,
   test3 int,
   test4 text,
   test5 uuid,
   test6 varchar,
   test7 varint,
   test8 duration,
   test9 smallint,
   test10 tinyint,
   test11 list<text>,
   test12 set<text>,
   test13 map<text,text>,
   test14 time
);

CREATE CUSTOM INDEX tweets_index ON demo.tweets ()
USING 'org.apache.second.ElasticSecondaryIndex'
WITH OPTIONS = {
   'refresh_seconds': '10',
   'schema': '{
      fields: {
         id: {type: "long"},
         user: {type: "text"},
         body: {type: "text", analyzer: "english"},
         time: {type: "date", pattern: "yyyy-MM-dd"},
         latitude: {type: "float"},
         longitude: {type:"float"},
         test:{type:"boolean"},
         test1:{type:"double"},
         test2:{type:"ip"},
         test3:{type:"integer"},
         test4:{type:"text"},
         test5:{type:"text"},
         test6:{type:"text"},
         test7:{type:"text"},
         test8:{type:"text"},
         test9:{type:"integer"},
         test10:{type:"integer"},
         test11:{type:"text"},
         test12:{type:"text"},
         test13:{type:"text"},
         test14:{type:"long"}
      }
   }'
};



INSERT INTO demo.tweets (id, user, body, time,latitude,longitude,test,test1,test2,test3,test4,test5,test6,test7,test8,test9,test10,test11,test12,test13,test14) VALUES (1, 'fu', textasblob('123456'),'2015-05-15',41.12,-71.34,true,12.33,'192.168.88.1',1,'lei1',now(),'a',9999,1h4m48s20ms,9,0,['a','b'],{'settext1','settext2'},{'a':'fu','b':'lei'},'04:05:00');


INSERT INTO demo.tweets (id, user, body, time,latitude,longitude,test,test1,test2,test3,test4,test5,test6,test7,test8,test9,test10,test11,test12,test13,test14) VALUES (2, 'fu', textasblob('123456'),'2019-05-15',41.12,-71.34,false,12.34,'192.168.88.3',2,'lei2',now(),'b',8888,2h4m48s20ms,8,8,['c','d'],{'abc1@gmail.com','xyz1@hotmail.com'},{'c':'fu','d':'lei'},'13:12:54');

INSERT INTO demo.tweets (id, user, body, time,latitude,longitude,test,test1,test2,test3,test4,test5,test6,test7,test8,test9,test10,test11,test12,test13,test14) VALUES (3, 'lei', textasblob('123456'),'2019-05-15',41.12,-71.34,true,12.35,'172.16.1.10',3,'lei3',now(),'c',7777,3h4m48s20ms,7,7,['e','f'],{'abc2@gmail.com','xyz2@hotmail.com'},{'e':'fu','f':'lei'},'22:12:54');
-----

====b.测试数据2
-----
######### 测试集合类型 ##########

CREATE TABLE demo.tweets_new (
   id bigint PRIMARY KEY,
   test1 list<text>,
   test2 set<text>,
   test3 map<text,text>
);


CREATE CUSTOM INDEX tweets_index_new ON demo.tweets_new ()
USING 'org.apache.second.ElasticSecondaryIndex'
WITH OPTIONS = {
   'refresh_seconds': '10',
   'schema': '{
      fields: {
         id: {type: "long"},
         test1:{type:"text"},
         test2:{type:"text"},
         test3:{type:"nested"}
      }
   }'
};

INSERT INTO demo.tweets_new (id,test1,test2,test3) VALUES (1,['a','b'],{'settext1','settext2'},{'a':'fu','b':'lei'});


INSERT INTO demo.tweets_new (id,test1,test2,test3) VALUES (2, ['c','d'],{'abc1@gmail.com','xyz1@hotmail.com'},{'c':'fu','d':'lei'});

INSERT INTO demo.tweets_new (id,test1,test2,test3) VALUES (3,['e','f'],{'abc2@gmail.com','xyz2@hotmail.com'},{'e':'fu','f':'lei'});
-----



